# WeChat AI Bot Configuration Example
# Copy this file to .env and update with your actual values

# Enable auto reply feature
WECHAT_AUTO_REPLY=true

# Delay in seconds before replying to messages
REPLY_DELAY=2

# Enable AI-powered replies
ENABLE_AI_REPLY=true

# LLM Model to use for generating responses
LLM_MODEL=mistral

# Host address for the LLM service
LLM_HOST=http://localhost:11434

# Request timeout (seconds) for LLM calls
LLM_TIMEOUT_S=60

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Maximum length of AI-generated responses
MAX_RESPONSE_LENGTH=200

# UI (Gradio)
# Only need to change when you want LAN access or a different port.
GRADIO_SERVER_NAME=127.0.0.1
GRADIO_SERVER_PORT=7860
